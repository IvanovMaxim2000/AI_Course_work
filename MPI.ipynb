{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTiixkMQSwqLSDpSHtFPKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanovMaxim2000/AI_Course_work/blob/main/MPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MPI\n"
      ],
      "metadata": {
        "id": "OyTl45widYWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Краткое описание"
      ],
      "metadata": {
        "id": "s5q2rgHpgTP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Message Passing Interface (MPI, интерфейс передачи сообщений) — программный интерфейс (API) для передачи информации, который позволяет обмениваться сообщениями между процессами, выполняющими одну задачу. Разработан Уильямом Гроуппом, Эвином Ласком (англ.) и другими.\n",
        "\n",
        "MPI является наиболее распространённым стандартом интерфейса обмена данными в параллельном программировании, существуют его реализации для большого числа компьютерных платформ. Используется при разработке программ для кластеров и суперкомпьютеров. Основным средством коммуникации между процессами в MPI является передача сообщений друг другу.\n",
        "\n",
        "Стандартизацией MPI занимается MPI Forum. В стандарте MPI описан интерфейс передачи сообщений, который должен поддерживаться как на платформе, так и в приложениях пользователя. В настоящее время существует большое количество бесплатных и коммерческих реализаций MPI. Существуют реализации для языков Фортран 77/90, Java, Си и C++.\n",
        "\n",
        "В первую очередь MPI ориентирован на системы с распределенной памятью, то есть когда затраты на передачу данных велики, в то время как OpenMP ориентирован на системы с общей памятью (многоядерные с общим кэшем). Обе технологии могут использоваться совместно, чтобы оптимально использовать в кластере многоядерные системы."
      ],
      "metadata": {
        "id": "BrctTFZng9K2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Постановка задачи:\n",
        "Необходимо провести ансамблевое голосование на управляющем ядре. Для этого отправляется отправляется модель и часть датасета на обучение всем процессам. После чего результаты предсказаний отправляются на нулевую ноду, и проводится голосование за более встречающийся результат.\n",
        "\n"
      ],
      "metadata": {
        "id": "1ur8Rva_pjoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка mpi4py"
      ],
      "metadata": {
        "id": "6E-fUBxshEwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuTcnVT_rqmU",
        "outputId": "81c066f5-e2f1-4b78-d167-f53b7e9de86f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 8.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp38-cp38-linux_x86_64.whl size=4438509 sha256=80f0f2c37f57b3de99c993577f0cb43eb3868674644306905dea0b59802f0890\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/35/48/0b9a7076995eea5ea64a7e4bc3f0f342f453080795276264e7\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "RDK0rsLrhVlY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ovgcYO9Kp1k2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25103c13-c540-4a6f-a6b6-9f27b38ca1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import mpi4py\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "\n",
        "from mpi4py import MPI\n",
        "\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow.keras as tk\n",
        "import operator\n",
        "import torch.utils.data as data_utils\n",
        "from torch.utils.data.dataset import random_split\n"
      ],
      "metadata": {
        "id": "ooDcf5DAp-NM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ca417a-78aa-4efc-ec1d-ca83c68efacd"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,                         \n",
        "    transform = ToTensor(), \n",
        "    download = True,            \n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data', \n",
        "    train = False, \n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiuWhZcPz0PJ",
        "outputId": "10878a26-f20c-40b5-a86a-85807092352c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Визуализация экземпляра данных"
      ],
      "metadata": {
        "id": "EriC_g8aj22v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data.data[0], cmap='gray')\n",
        "plt.title('%i' % train_data.targets[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWyMfRHjjw4j",
        "outputId": "9e66b555-3b30-4da9-98cd-87264b871250"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных для обучения с помощью DataLoaders"
      ],
      "metadata": {
        "id": "9lQI8W_ShimB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "from torch.utils.data import DataLoader\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "    \n",
        "    'test'  : torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "}\n",
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0rIOMbJ0F5S",
        "outputId": "ffe75f0b-7ac0-4b1b-cc97-18bb477467cd"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задаем модель сверточной нейронной сети"
      ],
      "metadata": {
        "id": "DBLQhaivhrJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in_channels (int) — Количество каналов во входном изображении\n",
        "\n",
        "out_channels (int) — Количество каналов, полученных сверткой\n",
        "\n",
        "kernel_size (int or tuple) — Размер свертывающегося ядра\n",
        "\n",
        "stride (int or tuple, optional) — Шаг свертки. Default: 1\n",
        "\n",
        "padding (int or tuple, optional) — Нулевое заполнение добавлено к обеим сторонам ввода. Default: 0\n",
        "\n",
        "padding_mode (string, optional) — ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’\n",
        "\n",
        "dilation (int or tuple, optional) — Расстояние между элементами ядра. Default: 1\n",
        "\n",
        "groups (int, optional) —Количество заблокированных соединений от входных каналов к выходным каналам. Default: 1\n",
        "\n",
        "bias (bool, optional) — Если True, к выходным данным добавляется обучаемое смещение.. Default: True"
      ],
      "metadata": {
        "id": "enD3ODt5hy72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "import torch.nn as nn\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=2,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        output = self.out(x)\n",
        "        return output, x    # return x for visualization"
      ],
      "metadata": {
        "id": "pHh9ZYqK0YLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da82ef47-9857-4298-ddbc-be69c6fd5552"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "cnn = CNN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS7fdGgd0fv_",
        "outputId": "b37a9c96-67d7-477c-97c6-277e338d9694"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Определяем функции потерь"
      ],
      "metadata": {
        "id": "7Z0pYMPMigV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "loss_func = nn.CrossEntropyLoss()   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICNFsaOA0jC_",
        "outputId": "47b46c0e-7a3a-4237-d193-90a312d2a717"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Определяем функцию оптимизации"
      ],
      "metadata": {
        "id": "CIxPovsnim0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZL5ocZl0ll8",
        "outputId": "64836b5f-c255-4957-fc6e-dafc098384bc"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение модели"
      ],
      "metadata": {
        "id": "N_PTGy7okMHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "from torch.autograd import Variable\n",
        "num_epochs = 10\n",
        "def train(train_num, num_epochs, cnn, loaders_trains):\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(cnn.parameters(), lr = 0.01)\n",
        "  cnn.train()\n",
        "\n",
        "  total_step = len(loaders_trains)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(loaders_trains):\n",
        "      batch_x = Variable(images)\n",
        "      batch_y = Variable(labels)\n",
        "\n",
        "      output = cnn(batch_x)[0]\n",
        "      loss = loss_func(output, batch_y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if (i + 1) % 100 == 0:\n",
        "        print('Train num {}, Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(train_num, \n",
        "                                                                              epoch + 1, \n",
        "                                                                              num_epochs, \n",
        "                                                                              i + 1,\n",
        "                                                                              total_step,\n",
        "                                                                              loss.item()))\n",
        "        pass\n",
        "      pass\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtVXa2vM0pI0",
        "outputId": "37e0b871-56d8-4e7d-e3c6-644270262d17"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка модели на тестовых данных"
      ],
      "metadata": {
        "id": "LEwvYv7xi2zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "def evaluate(cnn_for_test):\n",
        "  cnn_for_test.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in loaders['test']:\n",
        "      test_output, last_layer = cnn_for_test(images)\n",
        "      predicted = torch.max(test_output, 1)[1].data.squeeze()\n",
        "      accuracy = (predicted == labels).sum().item() / float(labels.size(0))\n",
        "      pass\n",
        "    print('Test accuracy : %.2f' % accuracy)\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkyZEpyBjXXQ",
        "outputId": "d8992deb-c97b-41da-b9c0-fce146384800"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка к использованию MPI"
      ],
      "metadata": {
        "id": "wTI5Qej3jcQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "comm = MPI.COMM_WORLD \n",
        "numprocs = comm.Get_size()\n",
        "rank = comm.Get_rank() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkDosHgWjRnk",
        "outputId": "17bdbfaf-6834-44a9-9b2c-dd69cf32b8c8"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка датасета"
      ],
      "metadata": {
        "id": "NsV1oZw8klQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "train_data = datasets.MNIST(root = 'data', train = True, \n",
        "                            transform = ToTensor(), download = True)\n",
        "\n",
        "test_data = datasets.MNIST(root = 'data', train = False, \n",
        "                          transform = ToTensor())\n",
        "\n",
        "train_part = int(len(train_data) / 3)\n",
        "\n",
        "\n",
        "image_indices = torch.arange(6000)\n",
        "cut_train = data_utils.Subset(train_data, image_indices)\n",
        "trains = random_split(cut_train, [2000, 2000, 2000])\n",
        "\n",
        "\n",
        "loaders = {'train1' : DataLoader(trains[0],\n",
        "                              batch_size = 100,\n",
        "                              shuffle = True,\n",
        "                              num_workers = 1),\n",
        "          'train2' : DataLoader(trains[1],\n",
        "                              batch_size = 100,\n",
        "                              shuffle = True,\n",
        "                              num_workers = 1),\n",
        "          'train3' : DataLoader(trains[2],\n",
        "                              batch_size = 100,\n",
        "                              shuffle = True,\n",
        "                              num_workers = 1),\n",
        "          'test' : DataLoader(test_data,\n",
        "                              batch_size = 100,\n",
        "                              shuffle = True,\n",
        "                              num_workers = 1)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdMUApGxTkXW",
        "outputId": "41f11870-6808-40b9-f0e1-0e569dc4df9e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Применение MPI"
      ],
      "metadata": {
        "id": "hPybZeTAlCye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a main.py\n",
        "printing_numbers = 25\n",
        "\n",
        "if rank != 0:\n",
        "\n",
        "  'Получаем объекты от нулевого процесса: модель, и части объема данных'\n",
        "  cnn = comm.recv(source = 0)\n",
        "  subset = comm.recv(source = 0)\n",
        "  train_num = comm.recv(source = 0)\n",
        "\n",
        "  num_epochs = 5\n",
        "\n",
        "  train(train_num, num_epochs, cnn, subset)\n",
        "  evaluate(cnn)\n",
        "\n",
        "  'Получаем изображение и делаем предсказание'\n",
        "  images = comm.recv(source = 0) \n",
        "\n",
        "  test_output, last_layer = cnn(images[:printing_numbers])\n",
        "  predicted = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
        "  preds_proc = comm.send(predicted, dest = 0)\n",
        "\n",
        "else:\n",
        "  'Отправляем другим процессам модель и части датасета'\n",
        "  for k in range(1, numprocs):\n",
        "    cnn = CNN()\n",
        "    train_num = 'train' + str(k)\n",
        "    comm.send(cnn, dest = k) \n",
        "    comm.send(loaders[train_num], dest = k) \n",
        "    comm.send(train_num, dest = k) \n",
        "\n",
        "  sample = next(iter(loaders['test']))\n",
        "  images, labels = sample\n",
        "  actual_number = labels[:printing_numbers].numpy()\n",
        "\n",
        "  'Отправляем изображение, которое хотим предугадать'\n",
        "  for k in range(1, numprocs):\n",
        "    comm.send(images, dest = k)\n",
        "\n",
        "  print(f'Actual number: {actual_number}')\n",
        "\n",
        "  'Получаем и записываем полученные результаты предсказания с других процессов'\n",
        "  predicted_numbers = []\n",
        "  for k in range(1, numprocs):\n",
        "    predicted = comm.recv(source = k)\n",
        "    predicted_numbers.append(predicted)\n",
        "\n",
        "  for k in range(1, numprocs):\n",
        "    print(f'[{k}] Prediction number: {predicted_numbers[k - 1]}')\n",
        "\n",
        "  'Голосавание ансамбля'\n",
        "  predicted_result = []  \n",
        "  for num in range(len(predicted_numbers[0])):\n",
        "    check_dict = {}\n",
        "    for k in range(1, numprocs):\n",
        "      current_number = predicted_numbers[k - 1][num] \n",
        "      num_count = check_dict.get(current_number, 0)\n",
        "      num_count = num_count + 1\n",
        "      check_dict[current_number] = num_count\n",
        "\n",
        "    max_vote_num = max(check_dict.items(), key = operator.itemgetter(1))[0]\n",
        "    predicted_result.append(max_vote_num)\n",
        "\n",
        "  print(f'Voting results: {predicted_result}'.replace(',', ''))\n",
        "  \n",
        "MPI.Finalize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWEz5dLDlB4q",
        "outputId": "b454051e-a517-44aa-c5e1-a8a3af48d6c4"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun -np 4 --allow-run-as-root python main.py"
      ],
      "metadata": {
        "id": "P8JfQSzKrZxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9f1d9a-a356-4be8-d3e8-2eabfd650974"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Test accuracy : 0.90\n",
            "Test accuracy : 0.93\n",
            "Test accuracy : 0.94\n",
            "Actual number: [2 6 7 9 6 7 5 8 7 7 4 6 7 7 3 7 2 9 4 8 6 1 5 5 8]\n",
            "[1] Prediction number: [2 6 7 9 6 7 5 8 7 7 4 6 7 7 3 7 2 9 4 8 6 1 5 5 8]\n",
            "[2] Prediction number: [2 6 7 9 6 7 5 8 7 7 4 6 7 7 3 7 2 9 4 8 6 1 5 5 8]\n",
            "[3] Prediction number: [2 6 7 9 6 7 5 8 7 7 4 4 7 7 3 9 2 9 4 8 6 1 5 5 2]\n",
            "Voting results: [2 6 7 9 6 7 5 8 7 7 4 6 7 7 3 7 2 9 4 8 6 1 5 5 8]\n"
          ]
        }
      ]
    }
  ]
}